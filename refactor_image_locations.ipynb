{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract | Extract data from pickle files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "metadata_path = '../cifar-100-python/meta'\n",
    "metadata = unpickle(metadata_path)\n",
    "superclass_dict = dict(list(enumerate(metadata[b'coarse_label_names'])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "data_pre_path = '../cifar-100-python/'\n",
    "\n",
    "# File paths\n",
    "data_train_path = data_pre_path + 'train'\n",
    "data_test_path = data_pre_path + 'test'\n",
    "\n",
    "# Read dictionary\n",
    "data_train_dict = unpickle(data_train_path)\n",
    "data_test_dict = unpickle(data_test_path)\n",
    "\n",
    "# Get data (change the coarse_labels if you want to use the 100 classes)\n",
    "data_train = data_train_dict[b'data']\n",
    "label_train = np.array(data_train_dict[b'coarse_labels'])\n",
    "data_test = data_test_dict[b'data']\n",
    "label_test = np.array(data_test_dict[b'coarse_labels'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform | Transform tensor to be in range [0,1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def transform_range_data(dataset):\n",
    "    dataset = dataset / 255\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "data_train = transform_range_data(data_train)\n",
    "data_test = transform_range_data(data_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transform | Retrieve mean and std of channel data in order to normalize data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def get_statistics_of_data(data, channel_nr):\n",
    "    channel_data_name = []\n",
    "    if channel_nr == 1:\n",
    "        channel_data_name = data[:,0:1024]\n",
    "    elif channel_nr == 2:\n",
    "        channel_data_name = data[:,1024:2048]\n",
    "    elif channel_nr == 3:\n",
    "        channel_data_name = data[:,2048:]\n",
    "\n",
    "    mean_of_channel = np.mean(channel_data_name)\n",
    "    std_of_channel = np.std(channel_data_name)\n",
    "    return mean_of_channel, std_of_channel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "first_mean, first_std = get_statistics_of_data(data_train, 1)\n",
    "second_mean, second_std = get_statistics_of_data(data_train, 2)\n",
    "third_mean, third_std = get_statistics_of_data(data_train, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5070751592371322 0.26733428587924063\n",
      "0.4865488733149497 0.25643846291708833\n",
      "0.44091784336703466 0.27615047132568393\n"
     ]
    }
   ],
   "source": [
    "print(first_mean, first_std)\n",
    "print(second_mean, second_std)\n",
    "print(third_mean, third_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[first_mean, second_mean, third_mean],\n",
    "                                 std=[first_std, second_std, third_std]\n",
    "                                 )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load | Create category folders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: b'aquatic_mammals',\n 1: b'fish',\n 2: b'flowers',\n 3: b'food_containers',\n 4: b'fruit_and_vegetables',\n 5: b'household_electrical_devices',\n 6: b'household_furniture',\n 7: b'insects',\n 8: b'large_carnivores',\n 9: b'large_man-made_outdoor_things',\n 10: b'large_natural_outdoor_scenes',\n 11: b'large_omnivores_and_herbivores',\n 12: b'medium_mammals',\n 13: b'non-insect_invertebrates',\n 14: b'people',\n 15: b'reptiles',\n 16: b'small_mammals',\n 17: b'trees',\n 18: b'vehicles_1',\n 19: b'vehicles_2'}"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superclass_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "dataset_path = \"../cifar-100-data\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "def extract_categories(dataset_path):\n",
    "    for category in superclass_dict:\n",
    "       train_indices = np.where(label_train == category)[0]\n",
    "       train_data = data_train[train_indices]\n",
    "\n",
    "       category_folder = os.path.join(dataset_path, str(category))\n",
    "       os.makedirs(category_folder, exist_ok=True)\n",
    "       np.save(os.path.join(category_folder, 'train_images.'), train_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extract_categories(dataset_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
